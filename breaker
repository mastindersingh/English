
# KPI Query Submission Guide

This guide helps you understand what types of queries you can submit to the KPI automation system. You can use **JIRA (JQL)**, **MSSQL**, or **PostgreSQL** queries.

---

## 1. JIRA Queries (JQL)

- Use to filter issues by project, status, labels, resolution, etc.
- Use placeholders `{start_date}` and `{end_date}` for dynamic dates.

**Example:**
```jql
project = "NTZQ" AND component = "PI_MAINTAIN"
AND status = "Hygiene"
AND issuetype IN (Epic, Sub-task)
AND labels = "PEMAP-1674"
AND resolutiondate >= "{start_date}"
AND resolutiondate <= "{end_date}"
```

---

## 2. MSSQL Queries

- Standard `SELECT` queries with filters and `GROUP BY`.
- Use column aliases like `AS my_date`, `AS metric_value`.

**Example:**
```sql
SELECT cm."APP_ID", cm."STATUS_CD", TRUNC("UPDATE_DT") AS my_date
FROM "PISI_AUTOMATION"."MA_CM" cm
JOIN common_lob lob ON cm.app_nm = lob.org_nm
WHERE cm."STATUS_CD" = 'Closed'
AND "UPDATE_DT" BETWEEN '{start_date}' AND '{end_date}'
GROUP BY cm."APP_ID", cm."STATUS_CD", TRUNC("UPDATE_DT")
```

---

## 3. PostgreSQL Queries

- Use for metrics sourced from Postgres DB.
- Return metric value, app ID, and date.

**Example:**
```sql
SELECT name, COUNT(*) AS count, DATE(created_at) AS my_date
FROM customer_logins
WHERE created_at BETWEEN '{start_date}' AND '{end_date}'
GROUP BY name, DATE(created_at)
```

---

## Guidelines

- Always include `{start_date}` and `{end_date}` for date filtering.
- Include `application_id` or org/ticket identifier.
- Avoid complex or unsafe operations (no INSERT, UPDATE, DELETE).
- Do not include PII or hardcoded secrets.

---

## What Not to Submit

- No schema-altering commands like `DROP`, `ALTER`
- No stored procedures or advanced dynamic SQL

---

## How to Submit

1. Prepare your query using the format above.
2. Submit via the Admin Panel or send it to the responsible admin.
3. It will be added to the system for scheduled execution.



flowchart TD
    A[Start Script] --> B[Connect to PostgreSQL]
    B --> C[Fetch KPI Measure List from KPI_MEASURES]
    C --> D{Datasource Name?}

    %% --- JIRA Branch ---
    D -->|JIRA| E[JIRA Auth via JiraProxy]
    E --> F[Execute JQL Query]
    F --> G[Extract Issue Data]
    G --> Z[Insert KPI Results into KPI_TRACKING]

    %% --- MSSQL Branch ---
    D -->|MSSQL| H[Connect to MSSQL]
    H --> I[Execute SQL Query from KPI_MEASURES.query_text]
    I --> J[Extract Result Rows]
    J --> Z

    %% --- PostgreSQL Branch (Optional / Self-query) ---
    D -->|PostgreSQL| K[Execute Query via PGSQL]
    K --> Z

    Z --> L[Commit to KPI_TRACKING]
    L --> M[Close All DB Connections]
    M --> N[End Script]

    %% --- Supporting Data Tables ---
    subgraph Data_Tables
        T1[KPI_MEASURES: Stores query_text & metric_name]
        T2[KPI_DATASOURCES: Contains JIRA / MSSQL / PG]
        T3[DATASOURCE_PROPERTIES: Env variable mappings]
        T4[KPI_TRACKING: Final output results]
    end

    B --> T1
    B --> T2
    B --> T3
    Z --> T4

Hi Peter,

I hope you’re doing well. I wanted to follow up on the referral made by Deepali Choudhary for the Lead Systems Operations Engineer position in your team.

I’ve applied for the role and am genuinely excited about the opportunity to contribute. With my background in EFT systems, Python, AWS, CI/CD, and automation, along with my recent experience at Wells Fargo as an Integration Engineer, I believe I can add value to your team.

If you’re available, I’d love the chance to connect and discuss the position further.

Looking forward to hearing from you.



GET .monitoring-es-*/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "type": "node_stats" } },
        { "exists": { "field": "node_stats.breakers" } }
      ]
    }
  },
  "sort": [
    { "timestamp": { "order": "desc" } }
  ],
  "_source": ["timestamp", "node_stats.node_id", "node_stats.breakers"]
}


